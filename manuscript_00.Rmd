---
title: 'Building the Million Transcriptome Ocular Meta-Atlas'
author:
  - Vinay Swamy:
      institute: bg
  - Temesgen Fufa:
      institute: mgog
  - Robert Hufnagel:
      institute: mgog
  - David McGaughey:
      institute:
        - bg
      correspondence: "yes"
      email: mcgaugheyd@mail.nih.gov
institute:
  - bg: Bioinformatics Group, Ophthalmic Genetics & Visual Function Branch, National Eye Institute, National Institutes of Health
  - mgog: Medical Genetics and Ophthalmic Genomics Unit, National Eye Institute, National Institutes of Health
    
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output:
  word_document:
    reference_docx: word-styles-reference-01.docx
    fig_caption: yes
    pandoc_args:
      - '--lua-filter=scholarly-metadata.lua'
      - '--lua-filter=author-info-blocks.lua'
bibliography: massive_integrated_eye_scRNA.bib
csl: investigative-ophthalmology-and-visual-science.csl
abstract: "The development of highly scalable single cell transcriptome technology has allowed for a high resolution view into huge numbers of single cell transcriptomes. Analyzing the transcriptomes between different projects is highly desirable as this would theoretically allow for better assessment of which effects are consistent across independent studies. However it is difficult to compare and contrast data across different projects as there are substantial batch effects from computational processing, single cell technology utilized, and the natural biological variation. While many single cell transcriptome specific batch correction methods purport to remove the technical noise it is difficult to ascertain which method works best. We developed an R package (scPOP) that can scan the results of multiple methods and key parameter choices and create a ranked list of the best performing method / parameter combinations. We use this package along with a Snakefile based workflow system to demonstrate how to optimally merge over 1.4 million cells from 30 datsets and three species to create a massive ocular single cell transcriptome meta-atlas. This provides a model how to efficiently create meta-atlases for tissues and cells of interest."
keywords: "RNA-seq, retina, RPE, ocular, eye, Snakemake, singlecell, scRNA, single-cell, singlecell, scPOP, R"
---

```{r Setup, message=FALSE, warning=FALSE, include=FALSE}
#knitr::opts_chunk$set(fig.pos = 'p') # Places figures on their own pages
knitr::opts_chunk$set(out.width = '100%', dpi=300)
library(tidyverse)
library(citr)
library(cowplot)
library(ggrepel)
library(colorspace)
library(flextable)
library(captioner)
library(pool)
library(RSQLite)
library(formattable)
library(ggalluvial)
library(scattermore)
library(grid)
library(ComplexHeatmap)
library(viridis)
# setup caption-ing
fig_cap <- captioner("Figure")
supFig_cap <- captioner("Supplemental Figure")
tab_cap <- captioner("Table")
supTab_cap <- captioner("Supplemental Table")

scEiaD_2020_v01 <- dbPool(drv = SQLite(), dbname = "~/data/massive_integrated_eye_scRNA/MOARTABLES__anthology_limmaFALSE___Mus_musculus_Macaca_fascicularis_Homo_sapiens-0-2000-counts-TabulaDroplet-batch-scVI-8-0.001-500-0.6.sqlite", idleTimeout = 3600000)

meta_filter <- fst::read_fst('~/git/plaeApp/inst/app/www/meta_filter.fst') %>% as_tibble()
meta_filter <- meta_filter %>% mutate(CellType_predict = case_when(CellType_predict == 'Photoreceptor Precursors' ~ 'PR Precursors',
                                                                   CellType_predict == 'AC/HC_Precurs' ~ 'AC/HC Precursors',
                                                                   CellType_predict == 'RPC' ~ 'RPCs',
                                                                   CellType_predict == 'Mesenchymal/RPE/Endothelial' ~ 'Endothelial',
                                                                   TRUE ~ CellType_predict)) 
# cells before QC removal (mito / likely doublets)
load('~/data/massive_integrated_eye_scRNA/cell_info_labelled.Rdata')

# meta data before doublet removal
load('~/data/massive_integrated_eye_scRNA/Mus_musculus_Macaca_fascicularis_Homo_sapiens__n_spec_genes-0__n_features2000__counts__TabulaDroplet__batch__scVI__dims8__preFilter__mindist0.001__nneighbors500.umap.Rdata')
umapRef <- umap

methods <- factor(c('scArches', 'bbknn','insct','magic', 'scVI','CCA', 'scanorama', 'harmony', 'fastMNN', 'combat', 'none', 'liger'), levels = c('bbknn','CCA','combat','fastMNN','harmony','insct','liger','magic','scanorama','scArches','scVI', 'none')) 

gse <- read_tsv('~/git/massive_integrated_eye_scRNA/data/GEO_Study_Level_Metadata.tsv')

qc <- readr::read_tsv('~/data/massive_integrated_eye_scRNA/QC.tsv.gz')
```


# Introduction
## Explosion of single cell transcriptomic atlases
The  recent introduction of relatively low cost and high throughput single cell sequencing technlogy has led to an explosion of research across many fields. As of 2020, over 30 million cells have been sequenced across over 1,000 studies (Svennson Pachter http://www.nxn.se/single-cell-studies). As of November 2020, the average size of each individual dataset is near 100,000 cells. Some of the seminal work in the high throughput single cell transcriptomics field (Macosko et al) have used the retina. As of late 2020, over a dozen published studies containing over a million cells have used single cell technology to profile cell type specific gene expression patterns, cell fate trajectory, tissue and cell differentiation, and disease perturbation. 

## Many researchers use processed count tables for methods development and hypothesis testing

While the gene - cell count tables are often made available in repositories like the Gene Expression Omnibus (GEO), there are no requirements to uniformly process the data. This means the count tables cannot be used in cross-study comparisons as even small differences in the computational pipeline (aligner, transcriptome reference, etc.) create study-specific effects. This issue can be addressed only by re-quantifying the data in a uniform environment. Fortunately, due to the continued development of computationally light-weight gene quantification tools into the single-cell space (kbtools, alevin-something), re-quantification does not require massive compute resources. 

Unfortunately, there still remain study specific batch effects due to the variety in single cell technologies used and variation in tissue handling and processing across different scientific groups. The single cell community has recognized that removal of these technical (also referred to as batch) effects is a critical issue and have independently developed many tools. It remains unclear which tool(s) is optimal for a particular dataset. 

<!-- Study specific web portals, should they exist, are silos which only contain the single cell transcriptomes related to their study. There are notable efforts to create web portals (UCSC Single Cell Browser, EBI Single Cell Expression Atlas) that allow for GUI-based viewing of data for most publicly available datasets. However, these again have the shortcoming as the study-specific web portals discussed above in that you still cannot directly compare between independent studies. In these situations it is impossible to compare directly across datasets. When exploring a gene expression pattern, it is crucial to have reproducibility across disparate groups to enhance confidence that effect is biological as bench experiments require large investments in time.  -->

<!-- ## Aggregation of results to create meta-atlas important -->

<!-- While these groups has leveraged this new technology to [do stuff], there is a large chasm to cross the enable outside groups to use the data in new ways. Several of these papers are accompanied by reactive web apps, which allow for relatively quick checks of gene expression across cell type or cluster assignment. However these web apps have minimal to no data exploration tools and are slow to operate, especially with the larger datasets.  -->

<!-- While lightly processed counts data is often provided, differences in both single cell technology (e.g. droplet or well based) and bioinformatic processing choices make it impossible to simply concatenate the datasets together as differences found will likely be technical.  -->

## The meta-atlas

We propose that by re-processing publicly available raw single cell transcriptome data in a consistent bioinformatic framework and optimally using batch correction tools we can create a meta-atlas, which combines individual datasets into one unified (or meta-) atlas. As there are thousands of possible permutations of single cell tools, references, and parameter choices, we create our meta-atlas (which we refer to as the single cell eye in a disk or scEiaD) by benchmarking integration outcomes across multiple important single cell RNA-seq processing parameters (integration tool, number of hyper-variable genes, clustering resolution, etc). The benchmarking system we developed uses a wide variety of metrics and we make available to all via an R package scPOP (single-cell Pick Optimal Parameters). The scEiaD will be of utility to two communities: the ocular community who can search scEiaD for gene expression across many dimensions (e.g. cluster, cell type, study) and the computational community who can use this very large, well-curated dataset to test algorithms for compute efficiency and performance in a diverse environment. As we believe data re-use is a powerful and accessible means to drive forward research, we provide our meta-atlas code-base and propose general guidelines to optimally create custom meta-atlases.

# Results

## We identify `r meta_filter %>% pull(study_accession) %>% unique() %>% length() - 1` ocular scRNA datasets across 3 species

The first step in building a meta-atlas is identifying studies to draw the data from. We identified ocular single cell RNA seq (scRNA) studies by querying PubMed, the Sequence Read Archive (SRA), and the European Nucleotide Archive (ENA) for the inclusive terms "retina", "single cell", "scRNA", "ocular", "eye", "transcriptome" and then hand filtering the results to only keep normal (non-perturbed or mutagenized) data from single cell RNA-seq technology. As of September 2020 we identified `r meta_filter %>% pull(study_accession) %>% unique() %>% length() - 1` deposited datasets that have been published in `r meta_filter %>% pull(Citation) %>% unique() %>% length()` publications (`r fig_cap(name = 'fig1', display = 'cite')`). To provide a non-ocular reference we also downloaded the raw sequence data for the Tabula Muris project. 
In cases where the fastq file from the SRA was not processed properly, we acquired the original bam files (personal correspondence or the SRA) and re-extracted the fastq. After downloading all the data we had 5.7 TB across `r scEiaD_2020_v01 %>% tbl('metadata_filter') %>% pull(sample_accession) %>% unique() %>% length()` fastq file sets. 

```{r fig1, fig.width=13, fig.height=6, fig.cap=fig1_cap, echo=FALSE, message = FALSE}
fig1_cap <- fig_cap(name='fig1', caption =  'a. Counts of (study) accession, published papers, and batches for each scRNA technlogy, split by organism. b. Simplified directed workflow of major steps in scEiaD creation from raw counts to gene counts, benchmarking optimal integration methods (SnakePOP) to produce batch corrected latent dimensions (LatentDims), then downstream analysis outputs like clustering, differential gene testing (DiffTesting), and 2D UMAP visualization. c. Cell type counts extracted from published studies for the more common retina cell types, split by species. Count of study accessions for each species overlaid on bar plot.')

source('figs_and_tables/fig1.R')
plot_grid(plot_grid(a, c, align = 'v',  axis = 'lr', ncol = 1, labels = c('','c')), b,  nrow = 1, rel_widths = c(1.1,1), labels = c('a','b'))
```

## `r cell_info_labels %>% nrow() %>% as.integer() %>% format(., big.mark=",", scientific=FALSE)` cells before quality control

Gene-level counts were quantified with the kallisto bustool pseudo-aligner for both the droplet and well based samples. For the droplet-based technology data, the inflection point between empty and non-empty droplets was automatically determined using the DropletUtils barcodeRank function in R. After empty droplet removal, we had `r format(cell_info_labels %>% nrow() %>% as.integer() , big.mark=",", scientific=FALSE)` cells. We then created a Seurat v3 object, calculated the percent mitochondrial genes counts, and removed cells which had more than 10% mitochondrial reads across all gene counts. For the droplet-based data, we also removed cells which had more than 3000 unique genes detected as these are likely to be doublets. After these standard quality control steps we were left with `r format(umapRef %>% nrow, big.mark = ",", scientific=FALSE)` cells. 

## Extraction and curation of cell type labels

A core objective of many scRNA based studies is labeling distinct cell types. As this information is crucial to assess dataset integration and provide an accurate reference for user querying, we extracted individual cell labels with a combination of hand-searching the Gene Expression Omnibus, supplemental information from the publication, web resources (if an web app was made available), and personal correspondence. After normalizing cell type names, we obtained labels for `r meta_filter$CellType %>% table() %>% sum()` cells across `r meta_filter$CellType %>% table() %>% length()` cell types (`r supTab_cap(name = 'supTab1_CTcounts', display = 'cite')`). 

## Running `r methods %>% length()` tools in a Snakefile-based system

Removal of the technical effects from the data is a crucial step in assessing the biological patterns out of the a meta-dataset. A wide variety of tools have been designed for this function. As we were uncertain which would perform the best and it is difficult to manually assess performance we ran `r methods %>% length()` tools with a commonly used set of key parameters that affect integration: 2000 hyper variable genes, 8 and 30 latent dimensions returned, and the louvain clustering algorithm with 7 k-nearest neighbors

There are two key metrics which have to be balanced in order to optimize performance: batch mixing (the same cell types should be similar across independent studies) and cell type or cluster purity (where different cell types or clusters should be distinct). While these can be visually assessed by looking at marker gene expression across the 2D t-SNE or UMAP projection, it is more rigorous and scalable to quantify this process.

We define batch as being each biological sample and assume each study is at least one unique sample. We studied the metadata and methods of each study to determine if the particular study contained multiple unique biological samples. In the end we identified `r umapRef %>% pull(batch) %>% unique() %>% length()` batches across `r umapRef %>% pull(study_accession) %>% unique() %>% length()` deposited datasets in `r umapRef %>% left_join(gse) %>% pull(PMID) %>% unique() %>% length()` published papers.

## scPOP wraps several different methods at measuring integration performance. 

scPOP brings together the Local Simpson Index (LISI) and Average Silhouette Width (ASW) metrics from Harmony and kBET, respectively, and the Adjusted Rand Index (ARI), Normalized Mutual Information (NMI), and PCR metrics from scIB. The LISI and ASW were used to measure batch mixing (where lower is better), cell type mixing (higher is better), and cluster mixing (higher is better). NMI and ARI were used to assess the consistency of cell type to cluster assignment (where 1 is perfect correspondence between cluster and cell type). The PCR metric (higher is better) runs PCA before and after integration to assess how much variance is explained by the batch corrected dimensional space. 

To visualize the interplay between batch mixing and cell type distinction we plot the batch mixing LISI score (which has been multiplied by -1) was plotted on the y-axis (higher is better) against the cluster LISI on the x-axis (higher is better). The best performer on both metrics will be in the top right corner  (`r supFig_cap(name = 'supFig_benchmark', display = 'cite')`a). In the same manner we plot the silhouette metric (`r supFig_cap(name = 'supFig_benchmark', display = 'cite')` b). 

## scPOP reveals different priorities across the different batch integration methods

On one extreme we have combat, which merges together different batches very well, but also mixes together the distinct cell types (`r fig_cap(name = 'figBenchmark', display = 'cite')`a). The other extreme is running the pipeline without any batch integration method, where you see very distinct groups of cells, but each study also is a distinct group in the 2D UMAP space (`r fig_cap(name = 'figBenchmark', display = 'cite')`b). In this dataset we see that like combat, Harmony  and CCA is weighed more towards batch mixing then cluster and cell type purity. Scanorama, fastMNN, and bbknn are more weighed to cleanly separate the clusters. With our scEiaD meta-atlas insct, scArches, and magic do not perform particularly well in batch mixing or cluster purity. 

## Different normalization methods alter integration performance

https://www.frontiersin.org/articles/10.3389/fgene.2020.00041/full
Another substantial area of uncertainty is expression normalization. A popular approach (which we call "standard") that Seurat and anndata use by default is to, per cell, divid the counts by the sum counts for the cell, multiply by a scaling factor, then log transform. This helps make the data more normal, which is an assumption that some algorithms require. In contrast, the scran normalization method groups cells into pools and normalizes across the pool summed counts instead of the individual cell counts. We also use the relatively simple square root (sqrt) normalization which replaces the log transformation with a square root. Library size (libSize) normalization omits the sqrt or log transformation. Finally some methods like scVI directly use the raw counts data for modeling the data. 

We see in the across the sumZScale metric, which we define as sumZScale = zscale(PCR) + zscale(LISI batch) + zscale(LISI cluster) + zscale(LISI cell type) + zscale(silhouette batch) + zscale(silhouette cluster) + zscale(silhouette cell type) + zscale(NMI) + zscale(ARI) that scVI overall performs best. As expected the libSize normalization which omits the log or square root scaling generally performs the worst (`r fig_cap(name = 'figBenchmark', display = 'cite')`c). We see that the remaining normalization approaches alters the batch correction performance, though the exact outcome differs across the different methods.  For users who have custom needs, the weights of each metrics can be customized in scPOP to prioritize batch mixing or cluster/cell type separation.

```{r figBenchmark, fig.width=14, fig.height=8, fig.cap=figBenchmark_cap, echo=FALSE, message = FALSE}
figBenchmark_cap <- fig_cap(name='figBenchmark', caption =  'a. Example of a method (combat) which has a high level of batch blending, but poor separation of cell types (colored by cell type). b. no batch correction cleanly separates cell types but does not mix batches (colored by study). c. sumZScale (higher is better) for each method across a variety of data normalizations. All methods shown here use 2000 HVG, louvain clustering, and 8 latent dimensions d. Optimal parameters for scVI methods across 1000 to 10000 HVGs and 4 to 100 latent dimensions.')

source('figs_and_tables/fig_umap_benchmarking.R')
plot_grid(
  plot_grid(
    umap_plot_maker(umapCombat), 
    umap_plot_maker(umapNone, color_against = 'study_accession'),
    rel_widths = c(1.3, 1),
    labels = c('a','b')), 
  plot_grid(
    zscore_sum_all_methods, 
    zscore_droplet_scVI_optimize,
    labels = c('c','d')),
  nrow = 2,
  rel_heights = c(1, 0.4)
)
```

## scVI has highest integration performance

scPOP finds that for our dataset scVI has the strongest performance, with a sum score of SOMETHING. The next highest performers are fastMNN, harmony, and scanorama. We do not claim that these results are general - rather we emphasize that for each (meta) atlas creation that scPOP or some similar unbiased approach where a range of several key parameters (e.g. HVG number) are tested in a quantitative framework. 

## Further optimization of scVI with grid search

To find the best set of parameters for integration and clustering we did a grid search across key parameters: hyper variable genes (HVG), latent dimensions, and k nearest neighbors. Using scPOP we found the optimal parameters to be 2000 HVG, 8 latent dimensions, and a resolution of 0.6 with the leiden algorithm implemented by XXXXX (`r fig_cap(name = 'figBenchmark', display = 'cite')`d). We also varied the UMAP projection values of nearest neighbors and minimum distance to qualitatively pick a 2D projection, selecting a minimum distance of 0.001 and 500 nearest neighbors. 

## xgboost ML model built to label unknown cell types
To further study cell type specific expression patterning we needed to label the `r format(umapRef %>% nrow() - meta_filter %>% filter(!is.na(CellType)) %>% nrow(), big.mark=",", scientific=FALSE)` unlabelled cells. Traditionally this is done by clustering the cells, then using cell type specific markers to label the clusters. However, as we had hundreds of thousands of expert labelled cells across `r umapRef %>% filter(!is.na(CellType)) %>% left_join(gse) %>% pull(PMID) %>% unique() %>% length()` studies (`r fig_cap(name = 'fig1', display = 'cite')`a) we built a xgboost-based machine learning model that used half of the labeled cells as a training set (see methods for more details) to train a cell type predictor for scEiaD input. The trained model was used to predict the cell type assignments for all cells in scEiaD. In this manner we both label most cells (cells which cannot be assigned a cell type assignment with a confidence above 0.5 were left unlabelled) and correct a small number of probable mislabels in the truth set (`r fig_cap(name = 'figXGboost_umap', display = 'cite')`a). 

## ML cell type predictor has high accuracy across most cell types
The precision recall (PR) curve visualizes the ability of the model to precisely label known cells at a given confidence. The area under the PR curve (AUC) summarizes the effectiveness of the model across different cell types, with 1 being the highest performance. The xgboost model can predict rods, bipolar cells, and Muller glia with near perfect performance (`r fig_cap(name = 'supFig_PR', display = 'cite')`). Most of the remaining cell types can be predicted with an AUC of well over 0.9. The cell types  that were the most challenging for the model to predict were the artery, choriocapillaris, and vein. Artery, choriocapillaris, and vein are constructed from endothelial cells. Indeed for all three of these, endothelial was the second most common label. The ML model also performs under 0.9 for predicting the neurogenic cell type label; however the most next common label that is predicts are the highly related retinal progenitor populations (RPCs) (`r supTab_cap(name = 'supTab_CTmislabels', display = 'cite')`). Overall, our xgboost based ML model shows strong accuracy across the major cell types of the retina. 

## Certain retina cell types have more stable community consensus IDs

With the wide diversity of the scEiaD we can get a sense on how consistent the retina community is at labelling the major cell types of the retina. By calculating the AUC against each individual cell type and study, we can see which cell types are consistently labeled correctly across most (`r fig_cap(name = 'supFig_PR_cap', display = 'cite')`). Most studies show very similar performance with our ML model. The study with the lowest correspondence between published and predicted label is Macoksko et al; this study is notable as it was the first demonstration of the droplet based scRNA technique.  

```{r figXGboost_umap, fig.width=18, fig.height=13, fig.cap=figXGboost_umap_cap, echo=FALSE, message = FALSE}
figXGboost_umap_cap <- fig_cap(name='figXGboost_umap', caption =  '')

source('figs_and_tables/sup_fig2__celltype_xgboost_labelling.R')
source('figs_and_tables/make_meta_scatter_umap_plot.R')
input <- list()
input[['meta_column']] <- 'CellType_predict'
input[['pt_size_meta']] <- 1
input[['gene_and_meta_scatter_tech']] <- 'Droplet'
input[['meta_column_transform']] <- 'None'
input[['label_toggle']] <- 2
#input[['meta_filter_cat']] <- 'CellType_predict'
#input[['meta_filter_on']] <- 'Bipolar Cells'
ctp <- make_meta_scatter_umap_plot(input, mf, meta_filter,
                                   celltype_predict_labels,
                                   celltype_labels,
                                   tabulamuris_predict_labels,
                                   cluster_labels,
                                   cat_to_color_df
)

input <- list()
input[['meta_column']] <- 'CellType_predict'
input[['pt_size_meta']] <- 2
input[['gene_and_meta_scatter_tech']] <- 'Droplet'
input[['meta_column_transform']] <- 'None'
#input[['meta_filter_cat']] <- 'CellType_predict'
#input[['meta_filter_on']] <- 'Bipolar Cells'
ctp2 <- make_meta_scatter_umap_plot(input, mf, meta_filter,
                                   celltype_predict_labels,
                                   celltype_labels,
                                   tabulamuris_predict_labels,
                                   cluster_labels,
                                   cat_to_color_df
)

input <- list()
input[['meta_column']] <- 'organism'
input[['pt_size_meta']] <- 1
input[['gene_and_meta_scatter_tech']] <- 'Droplet'
input[['meta_column_transform']] <- 'None'
#input[['meta_filter_cat']] <- 'CellType_predict'
#input[['meta_filter_on']] <- 'Bipolar Cells'
org <- make_meta_scatter_umap_plot(input, mf, meta_filter,
                                   celltype_predict_labels,
                                   celltype_labels,
                                   tabulamuris_predict_labels,
                                   cluster_labels,
                                   cat_to_color_df
)
plot_grid(grid.grabExpr(draw(ct_confusion)), 
          ctp$plot + theme(legend.position = "none"), 
          ctp2$plot + theme(legend.position = "none") + facet_wrap(~CellType_predict),
          org$plot + facet_wrap(~organism) + theme(legend.position = "none"), 
          ncol = 2,
          labels = c('a', 'b', 'c', 'd'),
          rel_heights = c(1,0.8)) 

```

## ML cell type labels result in study diversity for each cell type

After ML projection of cell type labels from the original `r meta_filter %>% filter(!is.na(CellType)) %>% nrow()` labels onto a total of `r meta_filter %>% filter(!is.na(CellType_predict) | !is.na(TabulaMurisCellType_predict)) %>% nrow()` cells we have substantially improved the number of studies per cell type. For example, we went from `r joinedSA %>% filter(CellType == 'Muller Glia') %>% pull(2)` human studies with labelled Muller Glia to `r joinedSA %>% filter(CellType == 'Muller Glia') %>% pull(5)` after labelling (`r supTab_cap(name = 'supTab_SAcounts', display = 'cite')`). Overall we go from an average of `r joinedSA %>% filter(CellType != 'Unlabelled') %>% pull(2) %>% mean()` studies per human cell type to `r joinedSA %>% filter(CellType != 'Unlabelled') %>% pull(5) %>% mean()` and `r joinedSA %>% filter(CellType != 'Unlabelled') %>% pull(4) %>% mean()` studies per mouse cell type to `r joinedSA %>% filter(CellType != 'Unlabelled') %>% pull(7) %>% mean()` after transferring the cell type labels. 

## The scVI-based scEiaD UMAP projection blends batches and separates cell types
The 2D UMAP projection of the scVI-calculated batch corrected 8 latent dimensional space blends the `r meta_filter %>% pull(study_accession) %>% unique() %>% length() - 1` studies together while also maintaining distinct space for the `r meta_filter$CellType_predict %>% table() %>% length()` unique cell types. We see the neurogenic populations from which the retinal cell types are derived near the center of the UMAP visualization. The photoreceptors (cones and rods) of the retina which are responsible for color and low-light vision, respectively, are near each other in the UMAP space. The amacrine cells ....say more about cell type in space

## Pseudobulk differential testing leverages high biological diversity to provide robust results

Differential gene expression testing between clusters or cell types in the single cell field usually involve using running the statistical test of choice with all individual cells across the group. In bulk RNA-seq the tests are done in relation to replicates, which are generally required. As we have a large number of replicates, we can sum our gene expression counts by group (e.g. celltype or cluster, split by organism and study). After this summing, we now have created a "pseudo-bulk" matrix. The statistical properties (CITE SOMETHING) are now similar to the traditional bulk RNA-seq experiment, allowing us to leverage the robust tooling. We use the edgeR test to run our differential expression tests. 

## Pan mouse as non-ocular reference to improve retina-specific gene search

Do some sloppy/easy thing where we identify retina specific genes by searching across the TM data?

# Methods

## Reproducblity

The full Snakemake pipeline that takes in the raw fastq sequence and outputs the scEiaD is at https://github.com/davemcg/scEiad. The publication commit is BLOOP. Furthermore, the repository has been deposited at zenodo under BLOOP. We will briefly discuss the pipeline choices, programs and algorithms, and versions below. For the R packages, we provide the versions as the supplementary file "R_session_info.txt"

## Quantification of gene counts

Kallisto (0.46.2) was the pseudoaligner. To reference transcriptomes used to build the kallisto index were the Gencode "gencode.vM25.annotation.gtf.gz" and "gencode.v35.annotation.gtf.gz" for mouse and human, respectively. The Ensembl release 99 "Macaca_mulatta.Mmul_10.99.gtf.gz" was used for the macaque transcriptome, For the relatively few single ended samples, the params "--single -l 200 -s 30" were used for kallisto quant. Otherwise the "--bias" flag was added. For the droplet-based samples, bustools (0.39.4) was used to extract the single cell barcodes, sort the output, and fix small barcoding errors.  

## Remove empty droplets and further QC.

After bustools count, we used the R environment (3.6.2) to remove empty droplets. The BUSpaRse package was used to input the bustools counts outputted mtx file. The DropletUtils package with the "barcodeRanks" function was used to automatically detect the inflection point in the barcode count ranks that distinguishes the likely empty droplets. After merging the individual count matrices into one matrix, we created a Seurat version 3 object and removed cells with a percent mitochondrial reads of >10%, fewer than 200 detected unique genes, and for the droplet data, more than 3000 detected genes. 

## Normalization and batch effect correction

We tested several gene count normalization approaches as we were not certain which would produce an optimal outcome: standard (default Seurat, library size normalization, then log transform), sqrt (same, but with sqrt normalization), libSize (omit the log or sqrt normalization), scran, SCT from Seurat, and for scVI, no normalization (counts). Our R implementation of the normalization approaches as well as how we constructed the Seurat v3 object can be found in the supplementary file "make_seurat_obj_functions.R"

## Batch normalization under a grid search procedure

We tested `r methods` against 2000 HVGs, the different gene count normalization procedures discussed above, and both 8 and 30 outputted batch corrected latent dimensions. The latent dimensions are the input for clustering, the 2D UMAP visualization, and the xgboost machine learning to transfer cell type labels to unlabelled cells. We were unable to run every method successfully with every normalization method. Magic could not complete with the standard or libSize normalization. CCA could not complete with the libSize normalization. We also tried the DESC, liber, and Conos batch corrections methods but were unable to get them to work reliably so they were not included. The batch correction step implementation can be found the supplementary file "merge_methods.R".

## Clustering and UMAP
Louvain-Jaccard clustering against the batch corrected latend dimensions used the Seurat implementation. We altered the k-nearest neighbors (knn) parameters to try 5, 7, and 10 (where 5 gives more clusters than 10). We also used the leiden algorith as implemented by PARC with a resolution of 0.6 and 0.8. These two resolutions were chosen as they roughly gave the same number of clusters at the Seurat Louvain-Jaccard with a knn 7. 

The UMAP visualization was also calculated with the Seurat implementation with the uwot R package. We altered the min.dist parameter with 0.001 and 0.1 and tried n.neighbors with 15, 30, 100, and 500. A smaller min.dist value gives "tighter" groupings while a higher number of n.neighbors uses a number of near cells the calculate the global positioning. 

## Benchmarking 

We wrote the scPOP R package to unify the LISI and Silhouette metrics from Harmony and kBet, respectively, along with NMI, ARI, and PCA variance explained before/after correction (PCR) which are implemented by scIB. As scIB is a python package, we brought over the tools with the basilisk package, which places a conda versioned python package which allows for easy installation without having to manage the python dependencies. 

To merge these metrics into a single score, we Z scale each and sum them. scPOP produces both tables and visualizations allowing the user to quickly see both the interplay of batch mixing and cluster/cell type separation and the overall performance. If a user wishes to prioritize batch mixing or cluster/cell type separation we let the user provide a custom batch/cluster-cell type scaling value (1 is the default). 

## Multi-step doublet removal
While we removed droplet-based cells with more than 3,000 transcripts as these are highly likely to be doublets (more than one cell per droplet) there are likely many more doublets. We ran DoubletDetect and scrublet and calculated the distribution of DoubletDetect and scrublet scores across all clusters and removed clusters with a DoubletDetect and scrublet score more than 4 standard deviations above the mean. This removed another `r format((umapRef %>% nrow() %>% as.integer()) - (meta_filter %>% nrow() %>% as.integer()), big.mark=",", scientific=FALSE)` cells, leaving `r format((meta_filter %>% nrow()) %>% as.integer(), big.mark=",", scientific=FALSE)` in total. 

## pseudobulk differential expression testing

Our pseudo-bulk differential testing was inspired by the OSCA guide. We computed differential tests for: cell type (published/transferred) against remaining cell types, celltype (published/transferred) pairwise against other individual celltype (published/transferred), specific cluster against remaining clusters, specific cluster against different individual cluster (pair-wise). Briefly, we grouped cells by the categories (e.g. each unique celltype (transferred) - study combination) and summed all gene counts. After summing the scores, we built a model matrix as 0 ~ categories + organism to remove any species specific effects. When then used the edgeR "estimateDisp" and tested the fit with "glmQLFit" and the parameter "robust = TRUE". Specific contrasts (e.g. Rods vs Cones) were differentially tested with "glmQLFTest".


# Conclusion

## Self built meta-atlases are easy as 1,2, benchmark a bunch, 3

## Projection of cell type labels from a smaller number of studies onto the remainining cells is a powerful way to increase diversity in a meta-atlas

## The scEiaD dataset provides a highly diverse, large N resource for methods development 

## The scEiaD is a unique ocular community resource  

## Fast algorithms are important 

# Supplemental
```{r supFig1, fig.width=4, fig.height=6, out.width=300, fig.cap=supFig1_cap, echo=FALSE, message = FALSE}
supFig1_cap <- supFig_cap(name='supFig1_cap', caption =  'The left bar delineates the number of cells for each organism - technology combination. The right bar specifies the number of each cells in each post QC category. In silico doublets were identified with scrublet and DoubletDetector.')

source('figs_and_tables/sup_fig1__qc_failure.R')
supFig1_plot
```


Words

Spacing



```{r supFig_benchmark, fig.width=12, fig.height=8, out.width=300, fig.cap=supFig_benchmark_cap, echo=FALSE, message = FALSE}
supFig_benchmark_cap <- supFig_cap(name='supFig_benchmark', caption =  'Performance of the various batch correction tools across various benchmarking metrics. For the LISI and Silhouette plots in A, B higher means better batch mixing and further to the right means better cluster purity. For the ARI and NMI metrics (which reflects how well cluster matches with cell type) in C, D, higher means a better score.')

source('figs_and_tables/fig2__integrationPerf.R')
cowplot::plot_grid(
  cowplot::plot_grid(lisi + theme(legend.position="none"), silhouette, NULL, rel_widths = c(1,1,0.2), nrow = 1, labels = c('a' ,'b')), 
  cowplot::plot_grid(ari, nmi, pcr, legend, rel_widths = c(1,1, 1, 0.2), ncol = 4, labels = c('c', 'd', 'e')), 
  nrow = 2)
```

Words

Spacing


```{r supTab1_CTcounts, fig.width=8, fig.height=14, out.width=300, fig.cap=supTab1_CTcounts_cap, echo=FALSE, message = FALSE}
supTab1_CTcounts_cap <- supTab_cap(name='supTab1_CTcounts_cap', caption =  'Counts for cell type labels. Published are the author created labels from the published datasets. Transferred area the cell labels that were transferred by a machine learning model onto the entire scEiaD dataset.')

source('figs_and_tables/sup_fig2__celltype_xgboost_labelling.R')
fontsize(ctTable, size = 8, part = 'all')
```



Words

Spacing



```{r supTab_SAcounts, fig.width=8, fig.height=14, out.width=300, fig.cap=supTab_SAcounts_cap, echo=FALSE, message = FALSE}
supTab_SAcounts_cap <- supTab_cap(name='supTab_SAcounts_cap', caption =  'Counts for number of studies with cell types labels before and after cell type label transfer')

source('figs_and_tables/sup_fig2__celltype_xgboost_labelling.R')
fontsize(saTable, size = 8, part = 'all')
```


Words

Spacing



```{r supFig_PR, fig.width=12, fig.height=10,  fig.cap=supFig_PR_cap, echo=FALSE, message = FALSE}
supFig_PR_cap <- supFig_cap(name='supFig_PR', caption =  '')

source('figs_and_tables/sup_fig__xgboost_PR.R')
pr_split_curves
```


Words

Spacing



```{r supTab_AUCxgboost, fig.cap=supTab_AUCxgboost_cap, echo=FALSE, message = FALSE}
supTab_AUCxgboost_cap <- supTab_cap(name='supTab_AUCxgboost', caption =  'TEXT')

#source('figs_and_tables/sup_fig2__celltype_xgboost_labelling.R')
fontsize(xgboost_pr_table_full %>% arrange(`Cell Type`, Study) %>% flextable() %>% width(width = 3), size = 8, part = 'all')
```


Words

Spacing




```{r supTab_CTmislabels, fig.width=2, fig.cap=supTab_CTmislabels_cap, echo=FALSE, message = FALSE}

supTab_CTmislabels_cap <- supTab_cap(name='supTab_CTmislabels', caption =  'TEXT2')

#source('figs_and_tables/sup_fig2__celltype_xgboost_labelling.R')
fontsize(predictions %>%  
           mutate(max_pred_prob = rowMaxs(.[,-(31:ncol(predictions))] %>% as.matrix )) %>% 
           select(-cell_type_id) %>% 
           rename(PredCellType = CellType) %>% 
           inner_join(umapRef %>% select(Barcode, TrueCellType = CellType)) %>% 
           filter(!is.na(TrueCellType)) %>% 
           mutate(pred_correct  = ifelse(PredCellType == TrueCellType, 'Correct', 'incorrect')) %>% 
           group_by(PredCellType, TrueCellType) %>% 
           summarise(Count = n()) %>% 
           mutate(Ratio  = round(Count / sum(Count),2 )) %>% 
           filter(Ratio > 0.05) %>% 
           filter(!grepl('Doubl|Periocu', TrueCellType)) %>% 
           flextable() %>% 
           autofit(), 
         size = 8, 
         part = 'all')
```


Words

Spacing




